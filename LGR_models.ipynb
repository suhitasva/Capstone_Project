{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f2f605",
   "metadata": {},
   "source": [
    "# Capstone project - HealthCare Fraud Detection : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a853647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve,roc_auc_score,f1_score\n",
    "from sklearn.metrics import classification_report as cl_rep_skl\n",
    "from imblearn.pipeline import Pipeline,make_pipeline\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from yellowbrick.classifier import confusion_matrix, classification_report, ROCAUC\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from cp_clean_helper import show_values\n",
    "from LGR_helper import std_num_cols, rb_scale_cols, model_results, get_confusion_matrix\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e748da",
   "metadata": {},
   "source": [
    "### # Loading datasets, dropping few columns, and looking at shapes:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0892d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original train data : (558211, 61)\n",
      "Shape of original test data : (135392, 60)\n",
      "Shape of model train data : (558211, 58)\n",
      "Shape of model test data : (135392, 57)\n"
     ]
    }
   ],
   "source": [
    "# Loading datasets\n",
    "\n",
    "train_df = pd.read_csv(\"clean_train.csv\",index_col=0)\n",
    "test_df = pd.read_csv(\"clean_test.csv\",index_col=0)\n",
    "\n",
    "# Dropping some ID related features and created new model dfs\n",
    "\n",
    "traindf = train_df.drop(['BeneID','ClaimID','Provider'], axis=1)\n",
    "testdf = test_df.drop(['BeneID','ClaimID','Provider'], axis=1)\n",
    "\n",
    "# Looking at dataset shapes\n",
    "\n",
    "print('Shape of original train data :',train_df.shape)\n",
    "print('Shape of original test data :',test_df.shape)\n",
    "print('Shape of model train data :',traindf.shape)\n",
    "print('Shape of model test data :',testdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04dd91",
   "metadata": {},
   "source": [
    "### # Separating independant and dependant variables:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36900d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoding PotentialFraud\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "traindf['PotentialFraud'] = label_encoder.fit_transform(traindf['PotentialFraud'])\n",
    "\n",
    "## Separating x and y variables for test train split\n",
    "\n",
    "LGR_x = traindf.drop(['PotentialFraud'], axis=1)\n",
    "LGR_y = traindf['PotentialFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671e0737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "558206    0\n",
       "558207    0\n",
       "558208    0\n",
       "558209    0\n",
       "558210    0\n",
       "Name: PotentialFraud, Length: 558211, dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGR_y # 1: Possible-fraud (Yes), 0: Non-fraud (No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2880984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    61.878931\n",
       "1    38.121069\n",
       "Name: PotentialFraud, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGR_y.value_counts(normalize=True)*100 # Imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8e01d",
   "metadata": {},
   "source": [
    "### # Train-Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8f67d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Shape of imbalanced trainX data : (390747, 57)\n",
      "Shape of imbalanced trainY data : (390747,)\n",
      "Shape of imbalanced testX data : (167464, 57)\n",
      "Shape of imbalanced testY data : (167464,)\n",
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "Class ratio - Fraud/Non-Fraud (trainY) : 0    61.878914\n",
      "1    38.121086\n",
      "Name: PotentialFraud, dtype: float64\n",
      "Class ratio - Fraud/Non-Fraud (testY) : 0    61.878971\n",
      "1    38.121029\n",
      "Name: PotentialFraud, dtype: float64\n",
      "\n",
      "\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Train test 70:30 split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(LGR_x, LGR_y, random_state=42,\\\n",
    "                                                shuffle=True, stratify=LGR_y, test_size=0.3)\n",
    "\n",
    "# Looking at dataset shapes\n",
    "\n",
    "print('\\n')\n",
    "print('Shape of imbalanced trainX data :',trainX.shape)\n",
    "print('Shape of imbalanced trainY data :',trainY.shape)\n",
    "print('Shape of imbalanced testX data :',testX.shape)\n",
    "print('Shape of imbalanced testY data :',testY.shape)\n",
    "print('\\n')\n",
    "print(\"*\"*60)\n",
    "\n",
    "# Looking at class ratios\n",
    "\n",
    "print('\\n')\n",
    "print('Class ratio - Fraud/Non-Fraud (trainY) :',trainY.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (testY) :',testY.value_counts(normalize=True)*100)\n",
    "print('\\n')\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c39f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping some additional features to evaluate performance\n",
    "\n",
    "trainX = trainX.drop(['NoOfMonths_PartACov', 'NoOfMonths_PartBCov','ChronicCond_Alzheimer',\\\n",
    "                            'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\\\n",
    "                            'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\\\n",
    "                            'ChronicCond_Depression', 'ChronicCond_Diabetes',\\\n",
    "                            'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\\\n",
    "                            'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke'], axis=1)\n",
    "\n",
    "testX = testX.drop(['NoOfMonths_PartACov', 'NoOfMonths_PartBCov','ChronicCond_Alzheimer',\\\n",
    "                          'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\\\n",
    "                          'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\\\n",
    "                          'ChronicCond_Depression', 'ChronicCond_Diabetes',\\\n",
    "                          'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\\\n",
    "                          'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e50b3",
   "metadata": {},
   "source": [
    "### # SMOTE Upsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling the minority class via SMOTE\n",
    "\n",
    "trainX_SM, trainY_SM = SMOTE(random_state=0, k_neighbors=7).fit_resample(trainX, trainY)\n",
    "testX_SM, testY_SM = SMOTE(random_state=0, k_neighbors=7).fit_resample(testX, testY)\n",
    "\n",
    "# Upsampling the minority class via Borderline SMOTE\n",
    "\n",
    "trainX_BSM, trainY_BSM = BorderlineSMOTE(random_state=0).fit_resample(trainX, trainY)\n",
    "testX_BSM, testY_BSM = BorderlineSMOTE(random_state=0).fit_resample(testX, testY)\n",
    "\n",
    "# Looking at dataset shapes\n",
    "\n",
    "print('\\n')\n",
    "print('Shape of SMOTE balanced trainX data :',trainX_SM.shape)\n",
    "print('Shape of SMOTE balanced trainY data :',trainY_SM.shape)\n",
    "print('Shape of SMOTE balanced testX data :',testX_SM.shape)\n",
    "print('Shape of SMOTE balanced testY data :',testY_SM.shape)\n",
    "print('Shape of Borderline SMOTE balanced trainX data :',trainX_BSM.shape)\n",
    "print('Shape of Borderline SMOTE balanced trainY data :',trainY_BSM.shape)\n",
    "print('Shape of Borderline SMOTE balanced testX data :',testX_BSM.shape)\n",
    "print('Shape of Borderline SMOTE balanced testY data :',testY_BSM.shape, end='\\n')\n",
    "print('\\n')\n",
    "print(\"*\"*60)\n",
    "\n",
    "# Looking at class ratios\n",
    "\n",
    "print('\\n')\n",
    "print('Class ratio - Fraud/Non-Fraud (trainY_SM) :',trainY_SM.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (testY_SM) :',testY_SM.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (trainY_BSM) :',trainY_BSM.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (testY_BSM) :',testY_BSM.value_counts(normalize=True)*100, end='\\n')\n",
    "print('\\n')\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e81e5",
   "metadata": {},
   "source": [
    "### # Saving the train/test SM/BSM files for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE files\n",
    "\n",
    "# trainX_SM.to_csv('trainX_SM.csv')\n",
    "# trainY_SM.to_csv('trainY_SM.csv')\n",
    "# testX_SM.to_csv('testX_SM.csv')\n",
    "# testY_SM.to_csv('testY_SM.csv')\n",
    "\n",
    "# BordelineSMOTE files\n",
    "\n",
    "# trainX_BSM.to_csv('trainX_BSM.csv')\n",
    "# trainY_BSM.to_csv('trainY_BSM.csv')\n",
    "# testX_BSM.to_csv('testX_BSM.csv')\n",
    "# testY_BSM.to_csv('testY_BSM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce79bc",
   "metadata": {},
   "source": [
    "### # Standardizing/Robust Scaling the train/test features for base SMOTE Balanced Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced Dataset\n",
    "\n",
    "# std_num_cols(trainX)\n",
    "# std_num_cols(testX)\n",
    "\n",
    "rb_scale_cols(trainX)\n",
    "rb_scale_cols(testX)\n",
    "\n",
    "# SMOTE balanced dataset\n",
    "\n",
    "# std_num_cols(trainX_SM)\n",
    "# std_num_cols(testX_SM)\n",
    "\n",
    "rb_scale_cols(trainX_SM)\n",
    "rb_scale_cols(testX_SM)\n",
    "\n",
    "# BorderlineSMOTE balanced dataset\n",
    "\n",
    "# std_num_cols(trainX_BSM)\n",
    "# std_num_cols(testX_BSM)\n",
    "\n",
    "rb_scale_cols(trainX_BSM)\n",
    "rb_scale_cols(testX_BSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cae1ff",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression Model - Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effef35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_logit = LogisticRegression(solver='liblinear')\n",
    "# model_results(trainX, trainY, testX, testY, base_logit, show=True)\n",
    "\n",
    "# base_logit = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "# model_results(trainX, trainY, testX, testY, base_logit, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383faf93",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression Model - SMOTE Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988db913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Logistic Regression Baseline Model\n",
    "\n",
    "# base_logitsm = LogisticRegression(solver='liblinear')\n",
    "# model_results(trainX_SM, trainY_SM, testX_SM, testY_SM, base_logitsm, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b151cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at confusion matrix\n",
    "\n",
    "# get_confusion_matrix(base_logitsm, testX_SM, testY_SM)\n",
    "\n",
    "# Visualizing the confusion matrix with Yellowbricks\n",
    "\n",
    "# plt.figure(figsize = (8,8))\n",
    "# confusion_matrix(\n",
    "#     base_logitsm,\n",
    "#     trainX_SM, trainY_SM, testX_SM, testY_SM,\n",
    "#     classes=['Non-Fraud', 'Possibly-Fraud']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e259f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at classification report\n",
    "\n",
    "# print(cl_rep_skl(testY_SM, base_logitsm.predict(testX_SM), target_names=['Non-Fraud','Possibly-Fraud']))\n",
    "\n",
    "# Visualizing the classification report with Yellowbricks\n",
    "\n",
    "# plt.figure(figsize = (12,6))\n",
    "# visualizer = classification_report(\n",
    "#     base_logitsm,\n",
    "#     trainX_SM, trainY_SM, testX_SM, testY_SM,\n",
    "#     classes=['Non-Fraud', 'Possibly-Fraud'],\n",
    "#     cmap='YlGnBu',\n",
    "#     support=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the AUC/ROC curve with sklearn function\n",
    "\n",
    "# plot_roc_curve(base_logitsm, trainX_SM, trainY_SM)\n",
    "\n",
    "# Visualizing the AUC/ROC curve with Yellowbricks\n",
    "\n",
    "# plt.figure(figsize = (14,12))\n",
    "\n",
    "# visualizer = ROCAUC(base_logitsm, classes=['Non-Fraud', 'Possibly-Fraud'])\n",
    "\n",
    "# visualizer.fit(trainX_SM, trainY_SM)        # Fit the training data to the visualizer\n",
    "# visualizer.score(testX_SM, testY_SM)        # Evaluate the model on the test data\n",
    "# visualizer.show()                           # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb675d8c",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression Model - Borderline SMOTE Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Logistic Regression Baseline Model\n",
    "\n",
    "# base_logitbsm = LogisticRegression(solver='liblinear')\n",
    "# model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, base_logitbsm, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at confusion matrix\n",
    "\n",
    "# get_confusion_matrix(base_logitbsm, testX_BSM, testY_BSM)\n",
    "\n",
    "# Visualizing the confusion matrix with Yellowbricks\n",
    "\n",
    "# plt.figure(figsize = (8,8))\n",
    "# confusion_matrix(\n",
    "#     base_logitbsm,\n",
    "#     trainX_BSM, trainY_BSM, testX_BSM, testY_BSM,\n",
    "#     classes=['Non-Fraud', 'Possibly-Fraud']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d341887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at classification report\n",
    "\n",
    "# print(cl_rep_skl(testY_BSM, base_logitbsm.predict(testX_BSM), target_names=['Non-Fraud','Possibly-Fraud']))\n",
    "\n",
    "# Visualizing the classification report with Yellowbricks\n",
    "\n",
    "# plt.figure(figsize = (12,6))\n",
    "# visualizer = classification_report(\n",
    "#     base_logitbsm,\n",
    "#     trainX_BSM, trainY_BSM, testX_BSM, testY_BSM,\n",
    "#     classes=['Non-Fraud', 'Possibly-Fraud'],\n",
    "#     cmap='YlGnBu',\n",
    "#     support=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the AUC/ROC curve with sklearn function\n",
    "\n",
    "# plot_roc_curve(base_logitbsm, trainX_BSM, trainY_BSM)\n",
    "\n",
    "# Visualizing the AUC/ROC curve with Yellowbricks\n",
    "\n",
    "# plt.figure(figsize = (14,12))\n",
    "\n",
    "# visualizer = ROCAUC(base_logitbsm, classes=['Non-Fraud', 'Possibly-Fraud'])\n",
    "\n",
    "# visualizer.fit(trainX_BSM, trainY_BSM)        # Fit the training data to the visualizer\n",
    "# visualizer.score(testX_BSM, testY_BSM)        # Evaluate the model on the test data\n",
    "# visualizer.show()                           # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac156404",
   "metadata": {},
   "source": [
    "### # Plotting scores versus different C values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad93780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_range = [1e8, 1e9, 1e10, 1e11]\n",
    "# C_range = [0.0001, 0.002]\n",
    "\n",
    "# train_error = []\n",
    "# test_error = []\n",
    "# train_AUC = []\n",
    "# test_AUC = []\n",
    "# train_F1 = []\n",
    "# test_F1 = []\n",
    "\n",
    "# for C in C_range:\n",
    "#     logit = LogisticRegression(solver='liblinear')\n",
    "#     logit.set_params(C=C)\n",
    "#     logit.fit(trainX_SM, trainY_SM)\n",
    "#     train_error.append(1 - logit.score(trainX_SM, trainY_SM))\n",
    "#     test_error.append(1 - logit.score(testX_SM, testY_SM))\n",
    "#     train_AUC.append(roc_auc_score(trainY_SM, logit.predict(trainX_SM)))\n",
    "#     test_AUC.append(roc_auc_score(testY_SM, logit.predict(testX_SM)))\n",
    "#     train_F1.append(f1_score(trainY_SM, logit.predict(trainX_SM)))\n",
    "#     test_F1.append(f1_score(testY_SM, logit.predict(testX_SM)))\n",
    "\n",
    "# plt.plot(C_range, train_error, c='red', label='Training Error')\n",
    "# plt.plot(C_range, test_error, c='blue', label='Test Error')\n",
    "# plt.ylabel('Errors')\n",
    "# plt.xlabel('C values')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(C_range, train_AUC, c='red', label='Training AUC Score')\n",
    "# plt.plot(C_range, test_AUC, c='blue', label='Test AUC Score')\n",
    "# plt.ylabel('AUC Scores')\n",
    "# plt.xlabel('C values')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(C_range, train_F1, c='red', label='Training F1 Score')\n",
    "# plt.plot(C_range, test_F1, c='blue', label='Test F1 Score')\n",
    "# plt.ylabel('F1 Scores')\n",
    "# plt.xlabel('C values')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b7832",
   "metadata": {},
   "source": [
    "## Using Grid Search to select best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting x and y variables\n",
    "\n",
    "x = trainX_SM \n",
    "y = trainY_SM\n",
    "\n",
    "# Setting model required parameters\n",
    "\n",
    "base_logitsm = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# Setting the parameter grid\n",
    "\n",
    "grid_para_logit = [{\n",
    "    \"C\": [0.0001, 0.01, 1, 100, 10000, 1000000, 100000000]}]\n",
    "\n",
    "# Running the RF model through the grid search\n",
    "\n",
    "grid_search_logit = GridSearchCV(base_logitsm, grid_para_logit,\\\n",
    "                                  cv=5, scoring='f1_weighted',\\\n",
    "                                  return_train_score = True, n_jobs=-1)\n",
    "\n",
    "grid_search_logit.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best parameters\n",
    "\n",
    "grid_search_logit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best score\n",
    "\n",
    "grid_search_logit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best estimator training/test errors\n",
    "\n",
    "print(\"The training error is: %.5f\" % (1 - grid_search_logit.best_estimator_.score(x, y)))\n",
    "print(\"The test     error is: %.5f\" % (1 - grid_search_logit.best_estimator_.score(testX_SM, testY_SM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the best model from the Grid Search as the final model\n",
    "\n",
    "final_lgr = grid_search_logit.best_estimator_\n",
    "\n",
    "# Model with all features and BSM:\n",
    "\n",
    "model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, final_lgr, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the discrimination threshold\n",
    "\n",
    "# from yellowbrick.classifier.threshold import discrimination_threshold\n",
    "\n",
    "# discrimination_threshold(final_lgr, trainX_BSM, trainY_BSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8498d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the threshold\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(trainY_BSM,final_lgr.predict_proba(trainX_BSM)[:,1],drop_intermediate=False)\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(thresholds,np.abs(fpr+tpr-1))\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"|FPR + TPR - 1|\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e14e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Actual value\n",
    "\n",
    "thresholds[np.argmin(np.abs(fpr+tpr-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1701f97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing the confusion matrix with Yellowbricks (thres=0.5)\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "confusion_matrix(\n",
    "    final_lgr,\n",
    "    trainX_BSM, trainY_BSM, testX_BSM, testY_BSM,\n",
    "    classes=['Non-Fraud', 'Possibly-Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at confusion matrix (thres=0.5)\n",
    "\n",
    "cm1 = get_confusion_matrix(final_lgr, testX_BSM, testY_BSM)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914292ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "\n",
    "labels = ['Non-Fraud', 'Possibly-Fraud']\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "ax = sns.heatmap(cm1, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix - Threshold (0.5)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744db65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at confusion matrix (thres=0.48)\n",
    "\n",
    "cm2 = get_confusion_matrix(final_lgr, testX_BSM, testY_BSM, thres=0.48)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "\n",
    "labels = ['Non-Fraud', 'Possibly-Fraud']\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "ax = sns.heatmap(cm2, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix - Threshold (0.5)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the AUC/ROC curve with Yellowbricks\n",
    "\n",
    "plt.figure(figsize = (14,12))\n",
    "\n",
    "visualizer = ROCAUC(final_lgr, classes=['Non-Fraud', 'Possibly-Fraud'])\n",
    "\n",
    "visualizer.fit(trainX_BSM, trainY_BSM)        # Fit the training data to the visualizer\n",
    "visualizer.score(testX_BSM, testY_BSM)        # Evaluate the model on the test data\n",
    "visualizer.show()                           # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing precision-recall curve\n",
    "\n",
    "from yellowbrick.classifier import precision_recall_curve\n",
    "\n",
    "plt.figure(figsize = (14,12))\n",
    "viz = precision_recall_curve(final_lgr, trainX_BSM, trainY_BSM, testX_BSM, testY_BSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing prediction error\n",
    "\n",
    "from yellowbrick.classifier import class_prediction_error\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "class_prediction_error(\n",
    "    final_lgr,\n",
    "    trainX_BSM, trainY_BSM, testX_BSM, testY_BSM,\n",
    "    classes=['Non-Fraud', 'Possibly-Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95688055",
   "metadata": {},
   "source": [
    "## BSM model performs better than SM version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f2a21",
   "metadata": {},
   "source": [
    "## SHAP Feature Importance Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767de53",
   "metadata": {},
   "source": [
    "### # Variable Importance Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(trainX_BSM).toarray()\n",
    "X_test = vectorizer.fit_transform(testX_BSM).toarray()\n",
    "explainer = shap.Explainer(final_lgr, X_train, feature_names=vectorizer.get_feature_names())\n",
    "shap_values = explainer(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989ba74",
   "metadata": {},
   "source": [
    "### # SHAP Dependence Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3109302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Total_Claim_Amt', shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('InscClaimAmtReimbursed', shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('DeductibleAmtPaid', shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('Gender', shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2dff7",
   "metadata": {},
   "source": [
    "### # Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Extracting top 10 best features with RFE:\n",
    "\n",
    "rfe = RFE(estimator=final_lgr, n_features_to_select=20, step=10)\n",
    "\n",
    "# Running model to compare performance\n",
    "\n",
    "model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, rfe, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58df2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at RFE feature selection\n",
    "\n",
    "print(trainX_BSM.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b2a2b",
   "metadata": {},
   "source": [
    "### # Feature Selection with SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976995f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Extracting top 20 best features by applying SelectKBest class\n",
    "\n",
    "bestfeatures = SelectKBest(k=20)\n",
    "fit = bestfeatures.fit(trainX_BSM, trainY_BSM)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(trainX_BSM.columns)\n",
    "\n",
    "#concat two dataframes\n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(20,'Score'))  #printing 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using SelectKBest 20 features\n",
    "\n",
    "selected_feat = featureScores.nlargest(20,'Score')['Features'].to_list()\n",
    "\n",
    "model_results(trainX_BSM[selected_feat], trainY_BSM, testX_BSM[selected_feat], testY_BSM, final_lgr, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
