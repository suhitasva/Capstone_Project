{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde91f3d",
   "metadata": {},
   "source": [
    "# Capstone project - HealthCare Fraud Detection : LightGBM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855ca026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,\\\n",
    "StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve,roc_auc_score,f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from yellowbrick.classifier import confusion_matrix, classification_report, ROCAUC\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from cp_clean_helper import show_values\n",
    "from LGR_helper import std_num_cols, rb_scale_cols, model_results, get_confusion_matrix\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560bb80e",
   "metadata": {},
   "source": [
    "### # Loading datasets, and looking at shapes:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdfd0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Shape of SMOTE balanced trainX data : (483580, 44)\n",
      "Shape of SMOTE balanced trainY data : (483580, 1)\n",
      "Shape of SMOTE balanced testX data : (207250, 44)\n",
      "Shape of SMOTE balanced testY data : (207250, 1)\n",
      "Shape of Borderline SMOTE balanced trainX data : (483580, 44)\n",
      "Shape of Borderline SMOTE balanced trainY data : (483580, 1)\n",
      "Shape of Borderline SMOTE balanced testX data : (207250, 44)\n",
      "Shape of Borderline SMOTE balanced testY data : (207250, 1)\n",
      "\n",
      "\n",
      "************************************************************\n",
      "\n",
      "\n",
      "Class ratio - Fraud/Non-Fraud (trainY_SM) : PotentialFraud\n",
      "0                 50.0\n",
      "1                 50.0\n",
      "dtype: float64\n",
      "Class ratio - Fraud/Non-Fraud (testY_SM) : PotentialFraud\n",
      "0                 50.0\n",
      "1                 50.0\n",
      "dtype: float64\n",
      "Class ratio - Fraud/Non-Fraud (trainY_BSM) : PotentialFraud\n",
      "0                 50.0\n",
      "1                 50.0\n",
      "dtype: float64\n",
      "Class ratio - Fraud/Non-Fraud (testY_BSM) : PotentialFraud\n",
      "0                 50.0\n",
      "1                 50.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Loading train-test 70:30 split (SMOTE and BorderlineSMOTE) datasets\n",
    "# For these same columns have been drooped as done for the LGR model\n",
    "\n",
    "trainX_SM = pd.read_csv(\"trainX_SM.csv\",index_col=0)\n",
    "trainY_SM = pd.read_csv(\"trainY_SM.csv\",index_col=0)\n",
    "testX_SM = pd.read_csv(\"testX_SM.csv\",index_col=0)\n",
    "testY_SM = pd.read_csv(\"testY_SM.csv\",index_col=0)\n",
    "\n",
    "trainX_BSM = pd.read_csv(\"trainX_BSM.csv\",index_col=0)\n",
    "trainY_BSM = pd.read_csv(\"trainY_BSM.csv\",index_col=0)\n",
    "testX_BSM = pd.read_csv(\"testX_BSM.csv\",index_col=0)\n",
    "testY_BSM = pd.read_csv(\"testY_BSM.csv\",index_col=0)\n",
    "\n",
    "# Looking at dataset shapes\n",
    "\n",
    "print('\\n')\n",
    "print('Shape of SMOTE balanced trainX data :',trainX_SM.shape)\n",
    "print('Shape of SMOTE balanced trainY data :',trainY_SM.shape)\n",
    "print('Shape of SMOTE balanced testX data :',testX_SM.shape)\n",
    "print('Shape of SMOTE balanced testY data :',testY_SM.shape)\n",
    "print('Shape of Borderline SMOTE balanced trainX data :',trainX_BSM.shape)\n",
    "print('Shape of Borderline SMOTE balanced trainY data :',trainY_BSM.shape)\n",
    "print('Shape of Borderline SMOTE balanced testX data :',testX_BSM.shape)\n",
    "print('Shape of Borderline SMOTE balanced testY data :',testY_BSM.shape, end='\\n')\n",
    "print('\\n')\n",
    "print(\"*\"*60)\n",
    "\n",
    "# Looking at class ratios\n",
    "\n",
    "print('\\n')\n",
    "print('Class ratio - Fraud/Non-Fraud (trainY_SM) :',trainY_SM.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (testY_SM) :',testY_SM.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (trainY_BSM) :',trainY_BSM.value_counts(normalize=True)*100)\n",
    "print('Class ratio - Fraud/Non-Fraud (testY_BSM) :',testY_BSM.value_counts(normalize=True)*100, end='\\n')\n",
    "print('\\n')\n",
    "print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40648c",
   "metadata": {},
   "source": [
    "### # Standardizing the train/test features for balanced datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9841d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE balanced dataset\n",
    "\n",
    "# std_num_cols(trainX_SM)\n",
    "# std_num_cols(testX_SM)\n",
    "\n",
    "# BorderlineSMOTE balanced dataset\n",
    "\n",
    "# std_num_cols(trainX_BSM)\n",
    "# std_num_cols(testX_BSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ad193",
   "metadata": {},
   "source": [
    "### Baseline LightGBM Classifier Model - Standardized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3183a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE Balanced\n",
    "\n",
    "# lgbm_std_sm = lgb.LGBMClassifier()\n",
    "# model_results(trainX_SM, trainY_SM, testX_SM, testY_SM, lgbm_std_sm, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daad3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BorderlineSMOTE Balanced\n",
    "\n",
    "# lgbm_std_bsm = lgb.LGBMClassifier()\n",
    "# model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, lgbm_std_bsm, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1ef90",
   "metadata": {},
   "source": [
    "### # Robust Scaling the train/test features for  balanced datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1233c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE balanced dataset\n",
    "\n",
    "rb_scale_cols(trainX_SM)\n",
    "rb_scale_cols(testX_SM)\n",
    "\n",
    "# BorderlineSMOTE balanced dataset\n",
    "\n",
    "rb_scale_cols(trainX_BSM)\n",
    "rb_scale_cols(testX_BSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189d0ad",
   "metadata": {},
   "source": [
    "### Baseline LightGBM Classifier Model - Robust Scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1994fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model Results for  LGBMClassifier()\n",
      "************************************************************\n",
      "Train Accuracy is equal to 0.792\n",
      "Test Accuracy is equal to 0.792\n",
      "The Precision score is 0.843\n",
      "The Average Precision score is 0.746\n",
      "The Recall score is 0.717\n",
      "The F1 score is 0.775\n",
      "The AUC/ROC score is 0.792\n",
      "True-Positive: 74318.000\n",
      "True-Negative: 89771.000\n",
      "False-Positive: 13854.000\n",
      "False-Negative: 29307.000\n",
      "Correctly Classified: 164089.000\n",
      "Incorrectly Classified: 43161.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7917697175234708,\n",
       " 0.7917442702050663,\n",
       " 0.8428752892074581,\n",
       " 0.7171821471652593]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE Balanced\n",
    "\n",
    "lgbm_sm = lgb.LGBMClassifier()\n",
    "model_results(trainX_SM, trainY_SM, testX_SM, testY_SM, lgbm_sm, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d072d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model Results for  LGBMClassifier()\n",
      "************************************************************\n",
      "Train Accuracy is equal to 0.792\n",
      "Test Accuracy is equal to 0.791\n",
      "The Precision score is 0.846\n",
      "The Average Precision score is 0.746\n",
      "The Recall score is 0.713\n",
      "The F1 score is 0.774\n",
      "The AUC/ROC score is 0.791\n",
      "True-Positive: 73883.000\n",
      "True-Negative: 90126.000\n",
      "False-Positive: 13499.000\n",
      "False-Negative: 29742.000\n",
      "Correctly Classified: 164009.000\n",
      "Incorrectly Classified: 43241.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7919620331692792,\n",
       " 0.7913582629674306,\n",
       " 0.8455173834428144,\n",
       " 0.7129843184559711]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BorderlineSMOTE Balanced\n",
    "\n",
    "lgbm_bsm = lgb.LGBMClassifier()\n",
    "model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, lgbm_bsm, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea7660",
   "metadata": {},
   "source": [
    "### # Plotting scores for different depth of trees in the random forest (SM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d28033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_range = range(9, 16)\n",
    "# train_error = []\n",
    "# test_error = []\n",
    "# train_AUC = []\n",
    "# test_AUC = []\n",
    "# train_F1 = []\n",
    "# test_F1 = []\n",
    "\n",
    "# for max_depth in depth_range:\n",
    "#     lg = lgb.LGBMClassifier()\n",
    "#     lg.set_params(max_depth=max_depth)\n",
    "#     lg.fit(trainX_SM, trainY_SM)\n",
    "#     train_error.append(1 - lg.score(trainX_SM, trainY_SM))\n",
    "#     test_error.append(1 - lg.score(testX_SM, testY_SM))\n",
    "#     train_AUC.append(roc_auc_score(trainY_SM, lg.predict(trainX_SM)))\n",
    "#     test_AUC.append(roc_auc_score(testY_SM, lg.predict(testX_SM)))\n",
    "#     train_F1.append(f1_score(trainY_SM, lg.predict(trainX_SM)))\n",
    "#     test_F1.append(f1_score(testY_SM, lg.predict(testX_SM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450ce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(depth_range, train_error, c='red', label='Training Error')\n",
    "# plt.plot(depth_range, test_error, c='blue', label='Test Error')\n",
    "# plt.ylabel('Errors')\n",
    "# plt.xlabel('Depth of trees')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3347c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(depth_range, train_AUC, c='red', label='Training AUC Score')\n",
    "# plt.plot(depth_range, test_AUC, c='blue', label='Test AUC Score')\n",
    "# plt.ylabel('AUC Scores')\n",
    "# plt.xlabel('Depth of trees')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f339c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(depth_range, train_F1, c='red', label='Training F1 Score')\n",
    "# plt.plot(depth_range, test_F1, c='blue', label='Test F1 Score')\n",
    "# plt.ylabel('F1 Scores')\n",
    "# plt.xlabel('Depth of trees')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311d080",
   "metadata": {},
   "source": [
    "### # Plotting scores for different number of trees in the random forest (SM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac2a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_range = [100,200,300,400,500]\n",
    "# train_error = []\n",
    "# test_error = []\n",
    "# train_AUC = []\n",
    "# test_AUC = []\n",
    "# train_F1 = []\n",
    "# test_F1 = []\n",
    "\n",
    "# for n_estimators in tree_range:\n",
    "#     lg = lgb.LGBMClassifier()\n",
    "#     lg.set_params(n_estimators=n_estimators)\n",
    "#     lg.fit(trainX_SM, trainY_SM)\n",
    "#     train_error.append(1 - lg.score(trainX_SM, trainY_SM))\n",
    "#     test_error.append(1 - lg.score(testX_SM, testY_SM))\n",
    "#     train_AUC.append(roc_auc_score(trainY_SM, lg.predict(trainX_SM)))\n",
    "#     test_AUC.append(roc_auc_score(testY_SM, lg.predict(testX_SM)))\n",
    "#     train_F1.append(f1_score(trainY_SM, lg.predict(trainX_SM)))\n",
    "#     test_F1.append(f1_score(testY_SM, lg.predict(testX_SM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d25a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(tree_range, train_error, c='red', label='Training Error')\n",
    "# plt.plot(tree_range, test_error, c='blue', label='Test Error')\n",
    "# plt.ylabel('Errors')\n",
    "# plt.xlabel('Number of trees')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1426a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(tree_range, train_AUC, c='red', label='Training AUC Score')\n",
    "# plt.plot(tree_range, test_AUC, c='blue', label='Test AUC Score')\n",
    "# plt.ylabel('AUC Scores')\n",
    "# plt.xlabel('Number of trees')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843bb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(tree_range, train_F1, c='red', label='Training F1 Score')\n",
    "# plt.plot(tree_range, test_F1, c='blue', label='Test F1 Score')\n",
    "# plt.ylabel('F1 Scores')\n",
    "# plt.xlabel('Number of trees')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76badba3",
   "metadata": {},
   "source": [
    "### # Plotting scores for different number of leaves in the random forest (SM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b98e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaves_range = [30,70,100,150,200]\n",
    "# train_error = []\n",
    "# test_error = []\n",
    "# train_AUC = []\n",
    "# test_AUC = []\n",
    "# train_F1 = []\n",
    "# test_F1 = []\n",
    "\n",
    "# for num_leaves in leaves_range:\n",
    "#     lg = lgb.LGBMClassifier()\n",
    "#     lg.set_params(num_leaves=num_leaves)\n",
    "#     lg.fit(trainX_SM, trainY_SM)\n",
    "#     train_error.append(1 - lg.score(trainX_SM, trainY_SM))\n",
    "#     test_error.append(1 - lg.score(testX_SM, testY_SM))\n",
    "#     train_AUC.append(roc_auc_score(trainY_SM, lg.predict(trainX_SM)))\n",
    "#     test_AUC.append(roc_auc_score(testY_SM, lg.predict(testX_SM)))\n",
    "#     train_F1.append(f1_score(trainY_SM, lg.predict(trainX_SM)))\n",
    "#     test_F1.append(f1_score(testY_SM, lg.predict(testX_SM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b0b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(leaves_range, train_error, c='red', label='Training Error')\n",
    "# plt.plot(leaves_range, test_error, c='blue', label='Test Error')\n",
    "# plt.ylabel('Errors')\n",
    "# plt.xlabel('Number of leaves')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0174ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(leaves_range, train_AUC, c='red', label='Training AUC Score')\n",
    "# plt.plot(leaves_range, test_AUC, c='blue', label='Test AUC Score')\n",
    "# plt.ylabel('AUC Scores')\n",
    "# plt.xlabel('Number of leaves')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "515680e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(leaves_range, train_F1, c='red', label='Training F1 Score')\n",
    "# plt.plot(leaves_range, test_F1, c='blue', label='Test F1 Score')\n",
    "# plt.ylabel('F1 Scores')\n",
    "# plt.xlabel('Number of leaves')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae188ae",
   "metadata": {},
   "source": [
    "## Using RandomizedSearchCV to select best parameters for SM dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d911ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting x and y variables\n",
    "\n",
    "# tr_x = trainX_SM\n",
    "# tr_y = trainY_SM\n",
    "# ts_x = testX_SM\n",
    "# ts_y = testY_SM\n",
    "\n",
    "# Setting up lgb_sm model\n",
    "\n",
    "# lgb_sm = lgb.LGBMClassifier()\n",
    "\n",
    "# Setting the parameter grid\n",
    "\n",
    "# grid_para_lgb = [{\n",
    "#     \"n_estimators\": [300,400,500],\n",
    "#     \"max_depth\": [12,13,14,15],\n",
    "#     \"learning_rate\": np.linspace(1e-2,1,20),\n",
    "#     \"colsample_bytree\" : [0.5,0.7,1,1.2],\n",
    "#     \"subsample\": [0.6,0.8,1,1.2],\n",
    "#     \"num_leaves\" : [100,125,150,175]}]\n",
    "\n",
    "# Running the XGB model through the grid search\n",
    "\n",
    "# grid_search_lgb = RandomizedSearchCV(lgb_sm, grid_para_lgb,\\\n",
    "#                                      cv=5,scoring='f1_weighted',verbose=1,\\\n",
    "#                                      return_train_score = True, n_jobs=-1)\n",
    "\n",
    "# grid_search_lgb.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29c3413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best parameters:\n",
    "\n",
    "# grid_search_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d29cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best score\n",
    "\n",
    "# grid_search_lgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2df69abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best estimator training/test errors\n",
    "\n",
    "# print(\"The training error is: %.5f\" % (1 - grid_search_lgb.best_estimator_.score(tr_x, tr_y)))\n",
    "# print(\"The test     error is: %.5f\" % (1 - grid_search_lgb.best_estimator_.score(ts_x, ts_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218dcb1d",
   "metadata": {},
   "source": [
    "## Using RandomizedSearchCV to select best parameters for BSM dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfabbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting x and y variables\n",
    "\n",
    "# tr_x = trainX_BSM\n",
    "# tr_y = trainY_BSM\n",
    "# ts_x = testX_BSM\n",
    "# ts_y = testY_BSM\n",
    "\n",
    "# Setting up xgb_sm model\n",
    "\n",
    "# lbg_bsm = lgb.LGBMClassifier()\n",
    "\n",
    "# Setting the parameter grid\n",
    "\n",
    "# grid_para_lgb = [{\n",
    "#     \"n_estimators\": [110,120,130],\n",
    "#     \"max_depth\": [6,6.5,7],\n",
    "#     \"learning_rate\": np.linspace(1e-2,1,20),\n",
    "#     \"colsample_bytree\" : [0.5,0.7,1,1.2],\n",
    "#     \"subsample\": [0.6,0.8,1,1.2],\n",
    "#     \"num_leaves\" : [100,125,150,175]}]\n",
    "\n",
    "# Running the XGB model through the grid search\n",
    "\n",
    "# grid_search_lgb = RandomizedSearchCV(lbg_bsm, grid_para_lgb,\\\n",
    "#                                      cv=5,scoring='f1_weighted',verbose=1,\\\n",
    "#                                      return_train_score = True, n_jobs=-1)\n",
    "\n",
    "# grid_search_lgb.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918a93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best parameters:\n",
    "\n",
    "# grid_search_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbe5364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best score\n",
    "\n",
    "# grid_search_lgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d5ad369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best estimator training/test errors\n",
    "\n",
    "# print(\"The training error is: %.5f\" % (1 - grid_search_lgb.best_estimator_.score(tr_x, tr_y)))\n",
    "# print(\"The test     error is: %.5f\" % (1 - grid_search_lgb.best_estimator_.score(ts_x, ts_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481cb05",
   "metadata": {},
   "source": [
    "### # Selecting the best model from the Grid Search as the final XGB SM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc670993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_sm = lgb.LGBMClassifier(subsample=0.8, n_estimators=400, num_leaves=175,\\\n",
    "#                       max_depth=13, learning_rate=0.2184, colsample_bytree=0.5)\n",
    "# model_results(trainX_SM, trainY_SM, testX_SM, testY_SM, lgb_sm, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9006c4c",
   "metadata": {},
   "source": [
    "### # Selecting the best model from the Grid Search as the final XGB BSM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34b70d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_bsm = lgb.LGBMClassifier(subsample=1, n_estimators=130, num_leaves=100,\\\n",
    "#                       max_depth=7, learning_rate=0.6352, colsample_bytree=1)\n",
    "# model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, lgb_bsm, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea3df02",
   "metadata": {},
   "source": [
    "### # Feature Selection with RFE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting top 20 best features with RFE:\n",
    "\n",
    "lgb_sm = lgb.LGBMClassifier(subsample=0.8, n_estimators=400, num_leaves=175,\\\n",
    "                      max_depth=13, learning_rate=0.2184, colsample_bytree=0.5)\n",
    "\n",
    "rfe1 = RFE(estimator=lgb_sm, n_features_to_select=20, step=10)\n",
    "\n",
    "# Running model to compare performance\n",
    "\n",
    "model_results(trainX_SM, trainY_SM, testX_SM, testY_SM, rfe1, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at RFE feature selection\n",
    "\n",
    "print(trainX_SM.columns[rfe1.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c31439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting top 20 best features with RFE:\n",
    "\n",
    "lgb_bsm = lgb.LGBMClassifier(subsample=1, n_estimators=130, num_leaves=100,\\\n",
    "                      max_depth=7, learning_rate=0.6352, colsample_bytree=1)\n",
    "\n",
    "rfe2 = RFE(estimator=lgb_bsm, n_features_to_select=20, step=10)\n",
    "\n",
    "# Running model to compare performance\n",
    "\n",
    "model_results(trainX_BSM, trainY_BSM, testX_BSM, testY_BSM, rfe2, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at RFE feature selection\n",
    "\n",
    "print(trainX_BSM.columns[rfe2.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07428596",
   "metadata": {},
   "source": [
    "### # Final models with selected features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using RFE 20 features\n",
    "\n",
    "lgb_sm = lgb.LGBMClassifier(subsample=0.8, n_estimators=400, num_leaves=175,\\\n",
    "                            max_depth=13, learning_rate=0.2184, colsample_bytree=0.5)\n",
    "\n",
    "selected_feat1 = trainX_SM.columns[rfe1.support_]\n",
    "\n",
    "model_results(trainX_SM[selected_feat1], trainY_SM, testX_SM[selected_feat1], testY_SM, xg_sm, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using RFE 20 features\n",
    "\n",
    "lgb_bsm = lgb.LGBMClassifier(subsample=1, n_estimators=130, num_leaves=100,\\\n",
    "                             max_depth=7, learning_rate=0.6352, colsample_bytree=1)\n",
    "\n",
    "selected_feat2 = trainX_BSM.columns[rfe2.support_]\n",
    "\n",
    "model_results(trainX_BSM[selected_feat2], trainY_BSM, testX_BSM[selected_feat2], testY_BSM, xg_bsm, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
